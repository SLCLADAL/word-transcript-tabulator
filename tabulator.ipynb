{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34495de-b0f6-490a-bc86-00359b542f96",
   "metadata": {},
   "source": [
    "# Word Transcript Tabulator Recipe\n",
    "\n",
    "This notebook is a computational recipe to help you to take a collection of transcripts in word documents (_docx_ only) and turn them into a structured tabular format suitable for working with computational analytics approaches.\n",
    "\n",
    "It will also:\n",
    "\n",
    "1. Help you check for and identify some inconsistencies in your transcripts (for example, missing and inconsistent speaker codes).\n",
    "2. Prepare a spreadsheet description of your dataset that can be converted to a standard metadata format (RO-Crate).\n",
    "\n",
    "## Assumptions and Preparation:\n",
    "\n",
    "- You have a set of transcripts as Microsoft Word (`.docx`) files.\n",
    "- Transcripts are formatted as one line/paragraph per speaker turn.\n",
    "- There is one speaker per turn, indicated by a speaker code at the start of the turn and ending with a colon (`:`) character.\n",
    "- Blank lines can be ignored.\n",
    "- No formatting of text is used to indicate important information: this process will remove styling information like *bold* and _italics_.\n",
    "- This won't be perfect: be prepared to spend time identifying and fixing errors.\n",
    "\n",
    "## This isn't for you if:\n",
    "\n",
    "1. You don't have your transcripts in Word format.\n",
    "2. You have formatted your transcripts as tables in Word.\n",
    "\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. Upload your transcripts in `.docx` format to the transcripts folder.\n",
    "2. Run the script to produce an initial file for examination and manual changes.\n",
    "4. Use the produced metadata to identify and fix inconsistencies in the transcripts *in word* - reupload any changed versions and try again.\n",
    "5. Fill in the metadata for speaker_codes and speakers. (Match codes in transcripts to speaker_ids, give details known about speakers).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e607c-dee7-4120-858d-0e75ac5cc6db",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "1. Upload your transcripts in `.docx` format into the `transcripts` folder on the left - you might might need to expand the left hand tab by clicking on the `icon of a folder`. Nested files are currently not supported.\n",
    "2. Run the code blocks below one at a time - you can run a code block by placing your cursor (clicking into) that cell and pressing the play button or entering the keyboard shortcut `shift-enter`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba96007-1784-41aa-a2ee-c21ee15dd7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘writexl’ was built under R version 4.4.3”\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the libraries we're going to use\n",
    "library(officer)\n",
    "library(writexl)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "\n",
    "# Define some helper functions: these are how we extract individual units of data from your transcripts\n",
    "\n",
    "# Do the initial extraction from a particular file\n",
    "prepare_transcripts <- function(transcript_file_path, speaker_regex, remove_speaker_regex){\n",
    "    print(transcript_file_path)\n",
    "    \n",
    "    # Load the file from word\n",
    "    transcript_df <- officer::docx_summary(officer::read_docx(transcript_file_path))\n",
    "    \n",
    "    # Remove any lines that contain only whitespace\n",
    "    transcript_df <- transcript_df %>%\n",
    "        filter(trimws(transcript_df$text) != '')\n",
    "    \n",
    "    # Attach the filepath as a column so we can trace this back\n",
    "    transcript_df$source_file <- basename(transcript_file_path)\n",
    "    \n",
    "    # Keep a copy of the original text so we can always compare the processing\n",
    "    transcript_df$source_text <- transcript_df$text\n",
    "    \n",
    "    # Extract the speaker codes via regex - match up to, but don't include the first colon.\n",
    "    transcript_df$speaker_code <- stringr::str_extract(transcript_df$source_text, speaker_regex)\n",
    "    \n",
    "    # And replace the original text with the speaker code removed\n",
    "    transcript_df$text <- NULL\n",
    "    transcript_df$text <- stringr::str_replace(transcript_df$source_text, remove_speaker_regex, \"\")    \n",
    "\n",
    "    return(transcript_df)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028932f-f4fc-4bff-81a3-b89db3019c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract Turns and Speaker Information\n",
    "\n",
    "This next block of code will load all of the transcript files you have uploaded and:\n",
    "\n",
    "1. Remove the headers.\n",
    "2. Extract the individual turns of speakers as rows.\n",
    "3. Join lines with leading whitespace (turns with manual line breaks) into single turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad2c595-8d47-4945-a1f8-c85d7e4289a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Loading: 6 transcripts:'"
      ],
      "text/latex": [
       "'Loading: 6 transcripts:'"
      ],
      "text/markdown": [
       "'Loading: 6 transcripts:'"
      ],
      "text/plain": [
       "[1] \"Loading: 6 transcripts:\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"transcripts/Transcrp-BethDaniel.docx\"\n",
      "[1] \"transcripts/Transcrp-HeatherMarie.docx\"\n",
      "[1] \"transcripts/Transcrp-LisaFiona.docx\"\n",
      "[1] \"transcripts/Transcrp-MarkKylie.docx\"\n",
      "[1] \"transcripts/Transcrp-NatalieKen.docx\"\n",
      "[1] \"transcripts/Transcrp-SuzanneLen.docx\"\n"
     ]
    }
   ],
   "source": [
    "# Now let's actually load your transcripts\n",
    "\n",
    "# List all of the docx files in the transcripts folder\n",
    "transcript_files = list.files(\"transcripts\", full.names=TRUE, pattern=\"*.docx\")\n",
    "\n",
    "paste0(\"Loading: \", length(transcript_files), \" transcripts:\") \n",
    "\n",
    "# The speaker code matches: a block of alphanumeric characters from the start of the turn,\n",
    "# up to, but not including the first colon. This will break if:\n",
    "# - the speaker code has a space\n",
    "speaker_regex <- '^[[:alpha:]]+?(?=:)'\n",
    "# This will match the speaker code, and the colon character, and any whitespace characters following.\n",
    "remove_speaker_regex <- '^[[:alpha:]]+?:[[:space:]]*'\n",
    "\n",
    "# TODO: figure out how to handle warnings without scaring people and ignoring them...\n",
    "# Load each transcript, extract the paragraphs of the document as rows in a dataframe, using the officer package\n",
    "loaded_docs <- lapply(transcript_files, prepare_transcripts, speaker_regex=speaker_regex, remove_speaker_regex=remove_speaker_regex)\n",
    "\n",
    "# Combine the transcripts together into a single dataframe.\n",
    "combined_transcripts <- bind_rows(loaded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287f7acd-728c-4f07-84db-d2a8e4bc2e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"../combined_transcripts.xlsx\" download><h2>Download your combined transcripts.</h2></a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now prepare three views of this dataset, and combine them with the existing data in the spreadsheet.\n",
    "# Merge or replace test?\n",
    "\n",
    "# Summary of the files and number of turns\n",
    "transcript_turns <- combined_transcripts %>% \n",
    "    group_by(source_file) %>% \n",
    "    summarise(turns=n(), speaker_count=n_distinct(speaker_code))\n",
    "\n",
    "# Info about the speaker-codes in each transcript\n",
    "speaker_code_summary <- combined_transcripts %>% \n",
    "    group_by(source_file, speaker_code) %>%\n",
    "    summarise(n_turns=n(), first_turn=min(doc_index), last_turn=max(doc_index), .groups=\"drop_last\")\n",
    "\n",
    "# Select and order columns for display\n",
    "output_turns <- combined_transcripts %>% \n",
    "    select(speaker_code, text, source_file, source_text, doc_index)\n",
    "\n",
    "# An (initially empty) table for speaker information\n",
    "sheets <- list(\n",
    "    transcripts = transcript_turns, \n",
    "    turns = output_turns, \n",
    "    speaker_codes = speaker_code_summary\n",
    ")\n",
    "\n",
    "write_xlsx(\n",
    "    sheets,\n",
    "    path='combined_transcripts.xlsx'\n",
    ")\n",
    "\n",
    "IRdisplay::display_html(\n",
    "    '<a href=\"../combined_transcripts.xlsx\" download><h2>Download your combined transcripts.</h2></a>'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
