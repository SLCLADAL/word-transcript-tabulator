{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34495de-b0f6-490a-bc86-00359b542f96",
   "metadata": {},
   "source": [
    "# Word Transcript Tabulator\n",
    "\n",
    "This notebook is a computational recipe to help you to take a collection of transcripts in word documents (_docx_ only) and turn them into a structured tabular format suitable for working with computational text analytics.\n",
    "\n",
    "As a side-effect of this, it will also help you check for and identify some inconsistencies in your transcripts (for example, inconsistent speaker identifiers).\n",
    "\n",
    "Note that this approach will remove all formatting from your text: if you have information in *bold*, _italics_, or elements highlighted in different colours that information will be lost in this process.\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "## Data Model\n",
    "\n",
    "## Libraries We'll Use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e607c-dee7-4120-858d-0e75ac5cc6db",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "1. Upload your transcripts in `.docx` format in the transcripts folder on the left. Nested files are currently not supported.\n",
    "2. Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba96007-1784-41aa-a2ee-c21ee15dd7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(officer)\n",
    "library(writexl)\n",
    "library(tidyverse)\n",
    "\n",
    "# Define some helper functions: these are how we extract individual units of data from your transcripts\n",
    "\n",
    "# Try to guess where a transcript might start after any header information - this can be fixed in the next step.\n",
    "guess_header_end <- function(doc_summary){\n",
    "  for (i in 1:nrow(doc_summary)){\n",
    "    row = doc_summary[i,]\n",
    "    # Header might end with a first blank line\n",
    "    if (trimws(row$text) == '') {\n",
    "      return(i)\n",
    "    }\n",
    "    # Header ends with first list paragraph style (ie, if you use numbered lists to generate turn numbers)\n",
    "    else if (!is.na(row$style_name) & row$style_name == 'List Paragraph'){\n",
    "      return(i)\n",
    "    }\n",
    "  }\n",
    "  # If we don't match any other rules, set the header to be zero lines long\n",
    "  # at the top of the file.\n",
    "  return(1)\n",
    "}\n",
    "\n",
    "# Extract the speaker codes for each turn. A speaker identifier is assumed to run from the start of the\n",
    "# turn to first colon (`:`).\n",
    "handle_speaker_codes <- function(doc_summary){\n",
    "    speaker_match = '^[[:alpha:]]+?(?=:)'\n",
    "    \n",
    "    # rearrange the file so that the original text is left as is\n",
    "    doc_summary$original_text <- doc_summary$text\n",
    "    matches = regexpr(speaker_match, doc_summary$text, perl = TRUE)\n",
    "    doc_summary$speaker_code <- regmatches(doc_summary$text, matches) \n",
    "    return(doc_summary)\n",
    "}\n",
    "\n",
    "# TODO: text without speakers, turn as originally entered\n",
    "# TODO: extract any timecodes\n",
    "\n",
    "# Do the initial extraction from a particular file\n",
    "extract_data <- function(transcript_file_path){\n",
    "    transcript_df <- officer::docx_summary(officer::read_docx(transcript_file_path))\n",
    "    \n",
    "    # Attach the filepath as a column so we can trace this back\n",
    "    transcript_df$source_file <- basename(transcript_file_path)\n",
    "    \n",
    "    return(transcript_df)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2c595-8d47-4945-a1f8-c85d7e4289a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's actually load your transcripts\n",
    "\n",
    "# List all of the docx files in the transcripts folder\n",
    "transcript_files = list.files(\"transcripts\", full.names=TRUE, pattern=\"*.docx\")\n",
    "\n",
    "\"Loading:\" \n",
    "transcript_files\n",
    "\n",
    "# Load each transcript, extract the paragraphs of the document as rows in a dataframe, using the officer package\n",
    "loaded_docs <- lapply(transcript_files, extract_data)\n",
    "\n",
    "# Extract the estimated point the header ends.\n",
    "# This is a stub for the segments table we'll need to generate to support this annotation.\n",
    "header_ends <- lapply(loaded_docs, guess_header_end)\n",
    "\n",
    "# Combine the transcripts together\n",
    "combined_transcripts <- bind_rows(loaded_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f7acd-728c-4f07-84db-d2a8e4bc2e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write out the transformed transcript\n",
    "header_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd8f75-de29-4cfc-bb10-415ca4f4d50f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "install.packages(\"tidyverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684aaa5e-8e4f-4ebd-b784-6237f6550cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
