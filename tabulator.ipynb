{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34495de-b0f6-490a-bc86-00359b542f96",
   "metadata": {},
   "source": [
    "# Word Transcript Tabulator Recipe\n",
    "\n",
    "This notebook is a computational recipe to help you to take a collection of transcripts in word documents (_docx_ only) and turn them into a structured tabular format suitable for working with computational analytics approaches.\n",
    "\n",
    "It will also:\n",
    "\n",
    "1. Help you check for and identify some inconsistencies in your transcripts (for example, missing and inconsistent speaker codes).\n",
    "2. Prepare a spreadsheet description of your dataset that can be converted to a standard metadata format (RO-Crate).\n",
    "\n",
    "## Assumptions and Preparation:\n",
    "\n",
    "- You have a set of transcripts as Microsoft Word (`.docx`) files.\n",
    "- Transcripts are formatted as one line/paragraph per speaker turn.\n",
    "- There is one speaker per turn, indicated by a speaker code at the start of the turn and ending with a colon (`:`) character.\n",
    "- The end of any header section is marked with 2 consecutive blank lines.\n",
    "- Blank lines can be ignored: except for the 2 consecutive blank lines indicating the end of the header.\n",
    "- No formatting of text is used to indicate important information: this process will remove styling information like *bold* and _italics_.\n",
    "- This won't be perfect: be prepared to spend time identifying and fixing errors.\n",
    "\n",
    "## This isn't for you if:\n",
    "\n",
    "1. You don't have your transcripts in Word format.\n",
    "2. You have formatted your transcripts as tables in Word.\n",
    "\n",
    "\n",
    "## Workflow Overview\n",
    "\n",
    "1. Upload your transcripts in `.docx` format to the transcripts folder.\n",
    "2. Run the script to produce an initial file for examination and manual changes.\n",
    "3. Check that the headers have been correctly been identified. (How???)\n",
    "4. Use the produced metadata to identify and fix inconsistencies in the transcripts *in word* - reupload any changed versions and try again.\n",
    "5. Fill in the metadata for speaker_codes and speakers. (Match codes in transcripts to speaker_ids, give details known about speakers).\n",
    "\n",
    "(This is going to need screenshots...)\n",
    "\n",
    "\n",
    "## Data Model\n",
    "\n",
    "\n",
    "## Libraries We'll Use\n",
    "\n",
    "\n",
    "## USECASE: while you're in data collection stage!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e607c-dee7-4120-858d-0e75ac5cc6db",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "1. Upload your transcripts in `.docx` format in the transcripts folder on the left. Nested files are currently not supported.\n",
    "2. Run the code blocks below one at a time - you can run a code block by placing your cursor (clicking into) that cell and pressing.\n",
    "\n",
    "## TODO: Breakdown the functions and explain them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba96007-1784-41aa-a2ee-c21ee15dd7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(officer)\n",
    "library(writexl)\n",
    "library(dplyr)\n",
    "library(stringr)\n",
    "\n",
    "# Define some helper functions: these are how we extract individual units of data from your transcripts\n",
    "\n",
    "# Identify the end of the header with two consecutive blank lines.\n",
    "filter_header_rows <- function(doc_summary){\n",
    "    prev_blank <- FALSE\n",
    "    \n",
    "    for (i in 1:nrow(doc_summary)){\n",
    "        row = doc_summary[i,]\n",
    "        \n",
    "        is_blank <- trimws(row$text) == ''\n",
    "        \n",
    "        if (!is_blank) {\n",
    "            prev_blank <- FALSE\n",
    "        }\n",
    "        \n",
    "        # Check for consecutive blanks and break.\n",
    "        if (is_blank & prev_blank) {\n",
    "            break\n",
    "        } else if (is_blank) {\n",
    "            prev_blank <- TRUE\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # If we can't find an end of header match, mark nothing as the header.\n",
    "    if (i == nrow(doc_summary)){\n",
    "        i <- 1\n",
    "    }\n",
    "       \n",
    "    # Slice out the header in the file.\n",
    "    return(doc_summary %>% slice(i:n()))\n",
    "}\n",
    "\n",
    "\n",
    "# TODO: extract any timecodes\n",
    "\n",
    "# Do the initial extraction from a particular file\n",
    "prepare_transcripts <- function(transcript_file_path, speaker_regex, remove_speaker_regex){\n",
    "    print(transcript_file_path)\n",
    "    \n",
    "    # Load the file from word\n",
    "    transcript_df <- officer::docx_summary(officer::read_docx(transcript_file_path))\n",
    "    \n",
    "    # Remove the header lines\n",
    "    transcript_df <- filter_header_rows(transcript_df)\n",
    "    \n",
    "    # Remove any lines that contain only whitespace\n",
    "    transcript_df <- transcript_df %>%\n",
    "        filter(trimws(transcript_df$text) != '')\n",
    "    \n",
    "    # Attach the filepath as a column so we can trace this back\n",
    "    transcript_df$source_file <- basename(transcript_file_path)\n",
    "    \n",
    "    # Keep a copy of the original text so we can always compare the processing\n",
    "    transcript_df$source_text <- transcript_df$text\n",
    "    \n",
    "    # Extract the speaker codes via regex - match up to, but don't include the first colon.\n",
    "    transcript_df$speaker_code <- stringr::str_extract(transcript_df$source_text, speaker_regex)\n",
    "    \n",
    "    # And replace the original text with the speaker code removed\n",
    "    transcript_df$text <- NULL\n",
    "    transcript_df$text <- stringr::str_replace(transcript_df$source_text, remove_speaker_regex, \"\")    \n",
    "\n",
    "    return(transcript_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028932f-f4fc-4bff-81a3-b89db3019c2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extract Turns and Speaker Information\n",
    "\n",
    "This next block of code will load all of the transcript files you have uploaded and:\n",
    "\n",
    "2. Remove the headers.\n",
    "1. Extract the individual turns of speakers as rows.\n",
    "3. Join lines with leading whitespace (turns with manual line breaks) into single turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad2c595-8d47-4945-a1f8-c85d7e4289a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's actually load your transcripts\n",
    "\n",
    "# List all of the docx files in the transcripts folder\n",
    "transcript_files = list.files(\"transcripts\", full.names=TRUE, pattern=\"*.docx\")\n",
    "\n",
    "paste0(\"Loading: \", length(transcript_files), \" transcripts:\") \n",
    "\n",
    "# The speaker code matches: a block of alphanumeric characters from the start of the turn,\n",
    "# up to, but not including the first colon. This will break if:\n",
    "# - the speaker code has a space\n",
    "speaker_regex <- '^[[:alpha:]]+?(?=:)'\n",
    "# This will match the speaker code, and the colon character, and any whitespace characters following.\n",
    "remove_speaker_regex <- '^[[:alpha:]]+?:[[:space:]]*'\n",
    "\n",
    "# TODO: figure out how to handle warnings without scaring people and ignoring them...\n",
    "# Load each transcript, extract the paragraphs of the document as rows in a dataframe, using the officer package\n",
    "loaded_docs <- lapply(transcript_files, prepare_transcripts, speaker_regex=speaker_regex, remove_speaker_regex=remove_speaker_regex)\n",
    "\n",
    "# Combine the transcripts together\n",
    "combined_transcripts <- bind_rows(loaded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f7acd-728c-4f07-84db-d2a8e4bc2e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now prepare three views of this dataset, and combine them with the existing data in the spreadsheet.\n",
    "# Merge or replace test?\n",
    "\n",
    "# Summary of the files and number of turns\n",
    "file_turns <- combined_transcripts %>% \n",
    "    group_by(source_file) %>% \n",
    "    summarise(turns=n(), speaker_count=n_distinct(speaker_code))\n",
    "\n",
    "\n",
    "# Info about the speaker-codes in each transcript\n",
    "speaker_code_summary <- combined_transcripts %>% \n",
    "    group_by(source_file, speaker_code) %>%\n",
    "    summarise(n_turns=n(), first_turn=min(doc_index), last_turn=max(doc_index))\n",
    "    \n",
    "\n",
    "# An (initially empty) table for speaker information\n",
    "sheets <- list(\n",
    "    transcripts = file_turns, \n",
    "    turns = combined_transcripts, \n",
    "    speaker_codes = speaker_code_summary\n",
    ")\n",
    "\n",
    "write_xlsx(\n",
    "    sheets,\n",
    "    path='combined_transcripts.xlsx'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684aaa5e-8e4f-4ebd-b784-6237f6550cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_transcripts %>% \n",
    "    group_by(source_file, speaker_code) %>%\n",
    "    summarise(n_turns=n(), first_turn=min(doc_index), last_turn=max(doc_index))\n",
    "\n",
    "combined_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a04b8-4165-440c-a592-f3f50265fdb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify and merge rows that appear to have manual linebreaks in a turn\n",
    "transcript_df <- combined_transcripts\n",
    "\n",
    "# Identify turns with leading whitespace, and where no valid speaker codes are present\n",
    "new_transcript <- transcript_df %>% \n",
    "    mutate(\n",
    "        leading_whitespace=stringr::str_detect(transcript_df$source_text, \"^[[:space:]]+\"),\n",
    "        has_speaker=!is.na(speaker_code)\n",
    "    )\n",
    "\n",
    "\n",
    "already_valid <- new_transcript %>% \n",
    "    filter(has_speaker) %>% \n",
    "    select(doc_index) %>% \n",
    "    rename(merge_with=doc_index)\n",
    "\n",
    "\n",
    "needs_merging <- new_transcript %>% \n",
    "    filter(!has_speaker) %>%\n",
    "    select(doc_index) %>%\n",
    "    left_join(already_valid, join_by(closest(doc_index>merge_with)))\n",
    "\n",
    "\n",
    "\n",
    "x <- new_transcript %>% \n",
    "    left_join(needs_merging, by=c('doc_index')) %>%\n",
    "    mutate(merge_with=coalesce(merge_with, doc_index)) %>%\n",
    "    group_by(merge_with) %>%\n",
    "    summarise(doc_index=min(doc_index), speaker_code=first(speaker_code), text=str_c(text, collapse=\" \")) %>%\n",
    "    select(!merge_with)\n",
    "\n",
    "write_xlsx(\n",
    "    x,\n",
    "    path='turns_combined.xlsx'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060db590-ffaa-4f73-b5f2-0c59cd39182f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
